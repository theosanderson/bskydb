# configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: bluesky
data:
  POSTGRES_DB: bluesky_posts
  POSTGRES_PASSWORD: dev-password-123  # Since DB isn't exposed, we can use a simple password
  init.sql: |
    CREATE TABLE IF NOT EXISTS posts (
      id SERIAL PRIMARY KEY,
      message_id TEXT NOT NULL UNIQUE, 
      did TEXT NOT NULL,
      post_text TEXT,
      timestamp_us BIGINT NOT NULL,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    
    CREATE INDEX IF NOT EXISTS idx_timestamp ON posts(created_at);
    CREATE INDEX IF NOT EXISTS idx_message_id ON posts(message_id);
    
    CREATE OR REPLACE FUNCTION cleanup_old_posts()
    RETURNS void AS $$
    BEGIN
      DELETE FROM posts 
      WHERE created_at < NOW() - INTERVAL '24 hours';
    END;
    $$ LANGUAGE plpgsql;

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: populator-script
  namespace: bluesky
data:
  package.json: |
    {
      "name": "bluesky-db-populator",
      "version": "1.0.0",
      "dependencies": {
        "ws": "^8.13.0",
        "pg": "^8.11.0",
        "pino": "^8.14.1"
      }
    }
  index.js: |
    const WebSocket = require('ws');
    const { Pool } = require('pg');
    const pino = require('pino');

    const logger = pino({
      level: 'info',
      timestamp: () => `,"time":"${new Date().toISOString()}"`,
    });

    const pool = new Pool({
      user: 'postgres',
      host: 'postgres',
      database: process.env.POSTGRES_DB,
      password: process.env.POSTGRES_PASSWORD,
      port: 5432,
    });

    const insertPostQuery = `
      INSERT INTO posts (message_id, did, post_text, timestamp_us)
      VALUES ($1, $2, $3, $4)
      ON CONFLICT (message_id) DO NOTHING
    `;

    async function connectToDatabase() {
      try {
        await pool.query('SELECT NOW()');
        logger.info('Successfully connected to PostgreSQL');
      } catch (err) {
        logger.error({ err }, 'Failed to connect to PostgreSQL');
        process.exit(1);
      }
    }

    async function insertPost(messageId, did, text, timeUs) {
      try {
        await pool.query(insertPostQuery, [messageId, did, text, timeUs]);
        logger.debug({ messageId }, 'Successfully inserted post');
      } catch (err) {
        logger.error({ err, messageId }, 'Failed to insert post');
      }
    }

    function connectToBlueskyFirehose() {
      const ws = new WebSocket('wss://bsky-relay.c.theo.io/subscribe?wantedCollections=app.bsky.feed.post');

      ws.on('open', () => {
        logger.info('Connected to Bluesky firehose');
      });

      ws.on('message', async (data) => {
        try {
          const message = JSON.parse(data);
          
          if (message.commit?.record?.text && 
              message.commit?.operation === 'create' && 
              message.commit?.collection === 'app.bsky.feed.post') {
            
            const messageId = message.commit.rkey;
            const did = message.did;
            const text = message.commit.record.text;
            const timeUs = message.time_us;

            await insertPost(messageId, did, text, timeUs);
          }
        } catch (err) {
          logger.error({ err }, 'Error processing message');
        }
      });

      ws.on('error', (error) => {
        logger.error({ error }, 'WebSocket error');
      });

      ws.on('close', () => {
        logger.warn('Disconnected from Bluesky firehose, attempting to reconnect in 5 seconds...');
        setTimeout(connectToBlueskyFirehose, 5000);
      });
    }

    async function main() {
      await connectToDatabase();
      connectToBlueskyFirehose();
    }

    main().catch((err) => {
      logger.error({ err }, 'Application failed to start');
      process.exit(1);
    });

---
# postgres infrastructure
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: bluesky
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: bluesky
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
        - name: postgres
          image: postgres:15
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_DB
            - name: POSTGRES_PASSWORD
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_PASSWORD
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata  # Changed this line
          volumeMounts:
            - name: postgres-storage
              mountPath: /var/lib/postgresql/data
            - name: init-script
              mountPath: /docker-entrypoint-initdb.d
      volumes:
        - name: postgres-storage
          persistentVolumeClaim:
            claimName: postgres-pvc
        - name: init-script
          configMap:
            name: postgres-config
            items:
              - key: init.sql
                path: init.sql

---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: bluesky
spec:
  selector:
    app: postgres
  ports:
    - port: 5432
      targetPort: 5432
  type: ClusterIP

---
# cleanup job
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-cleanup
  namespace: bluesky
spec:
  schedule: "0 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: postgres-cleanup
              image: postgres:15
              command:
                - /bin/sh
                - -c
                - |
                  PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -d bluesky_posts -c "SELECT cleanup_old_posts();"
              env:
                - name: POSTGRES_PASSWORD
                  valueFrom:
                    configMapKeyRef:
                      name: postgres-config
                      key: POSTGRES_PASSWORD
          restartPolicy: OnFailure

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bluesky-populator
  namespace: bluesky
spec:
  replicas: 1
  selector:
    matchLabels:
      app: bluesky-populator
  template:
    metadata:
      labels:
        app: bluesky-populator
    spec:
      initContainers:
        - name: install-deps
          image: node:18-slim
          command: 
            - /bin/sh
            - -c
            - |
              cp /config/* /app/
              cd /app
              npm install
          volumeMounts:
            - name: script-volume
              mountPath: /config
            - name: app-volume
              mountPath: /app
      containers:
        - name: populator
          image: node:18-slim
          command: ['node', 'index.js']
          workingDir: /app
          env:
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_DB
            - name: POSTGRES_PASSWORD
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_PASSWORD
          volumeMounts:
            - name: app-volume
              mountPath: /app
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "200m"
      volumes:
        - name: script-volume
          configMap:
            name: populator-script
        - name: app-volume
          emptyDir: {}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: iambic-monitor-config
  namespace: bluesky
data:
  iambic_monitor.py: |
    import nltk
    from nltk.corpus import cmudict
    import itertools
    import re
    from collections import defaultdict
    from functools import lru_cache
    import json
    import asyncio
    import websockets
    import psycopg2
    import logging
    import os
    from datetime import datetime
    from contextlib import contextmanager

    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    # Download required NLTK data
    nltk.download('cmudict', quiet=True)
    pronouncing_dict = cmudict.dict()

    # Create word stress patterns cache
    word_stress_patterns = defaultdict(list)
    for word, pronunciations in pronouncing_dict.items():
        word_stress_patterns[word] = [
            [int(phoneme[-1]) for phoneme in pron if phoneme[-1] in '012']
            for pron in pronunciations
        ]

    # Text processing utilities
    substitutions = {
        '&': ' and ',
        'w/': 'with',
        'w/o': 'without',
    }

    banned = ['$', '#', '@', '/']

    def num2words(num):
        """Convert number to words."""
        under_20 = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven',
                    'Eight', 'Nine', 'Ten', 'Eleven', 'Twelve', 'Thirteen', 'Fourteen',
                    'Fifteen', 'Sixteen', 'Seventeen', 'Eighteen', 'Nineteen']
        tens = ['Twenty', 'Thirty', 'Forty', 'Fifty', 'Sixty', 'Seventy', 'Eighty', 'Ninety']
        above_100 = {100: 'Hundred', 1000: 'Thousand', 1000000: 'Million', 1000000000: 'Billion'}

        if num < 20:
            return under_20[num]
        if num < 100:
            return tens[(num // 10) - 2] + ('' if num % 10 == 0 else ' ' + under_20[num % 10])
        pivot = max([key for key in above_100.keys() if key <= num])
        return num2words(num // pivot) + ' ' + above_100[pivot] + ('' if num % pivot == 0 else ' ' + num2words(num % pivot))

    def numerals_to_words(text):
        """Convert numerals to words in text."""
        return re.sub(r'(\d+)', lambda m: num2words(int(m.group(0))), text)

    def is_iambic_pentameter(pattern):
        """Check if a stress pattern is iambic pentameter."""
        return len(pattern) == 10 and all(
            (s == 0 or s == 2) if i % 2 == 0 else s == 1
            for i, s in enumerate(pattern)
        )

    @lru_cache(maxsize=10000)
    def check_iambic_pentameter(text):
        """Check if text is in iambic pentameter."""
        if len(text.split()) < 5 or len(text.split()) > 75:
            return False
        
        if any(b in text for b in banned):
            return False
        
        for k, v in substitutions.items():
            text = text.replace(k, v)
        
        text = numerals_to_words(text)
        text = re.sub(r'[^A-Za-z\s\']', '', text.lower())
        text = re.sub(r'\s+', ' ', text)
        words = text.split()
        
        if len(set(words)) == 1:
            return False
        
        if not all(word in word_stress_patterns for word in words):
            return False
        
        stress_options = [word_stress_patterns[word] for word in words]
   
        
        min_syllables = sum(min(len(patterns) for patterns in p) for p in stress_options)
        max_syllables = sum(max(len(patterns) for patterns in p) for p in stress_options)
        if min_syllables > 10 or max_syllables < 10:
            return False
        
        for stress_combination in itertools.product(*stress_options):
            pattern = [s for stresses in stress_combination for s in stresses]
            if is_iambic_pentameter(pattern):
                return True
        return False

    class DatabaseManager:
        def __init__(self):
            self.db_params = {
                'dbname': os.environ['POSTGRES_DB'],
                'user': 'postgres',
                'password': os.environ['POSTGRES_PASSWORD'],
                'host': 'postgres',
                'port': 5432
            }

        @contextmanager
        def get_connection(self):
            """Context manager for database connections."""
            conn = None
            try:
                conn = psycopg2.connect(**self.db_params)
                yield conn
            except Exception as e:
                if conn:
                    conn.rollback()
                raise
            finally:
                if conn:
                    conn.close()

        def init_db(self):
            """Initialize database schema."""
            with self.get_connection() as conn:
                with conn.cursor() as cur:
                    # Create table if it doesn't exist
                    create_table_query = """
                    CREATE TABLE IF NOT EXISTS iambic_messages (
                        id SERIAL PRIMARY KEY,
                        message_id TEXT NOT NULL UNIQUE,
                        did TEXT NOT NULL,
                        post_text TEXT NOT NULL,
                        timestamp_us BIGINT NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        reposted_at TIMESTAMP
                    );
                    """
                    
                    # Create indices
                    create_indices = """
                    CREATE INDEX IF NOT EXISTS idx_iambic_timestamp ON iambic_messages(created_at);
                    CREATE INDEX IF NOT EXISTS idx_iambic_message_id ON iambic_messages(message_id);
                    """
                    
                    cur.execute(create_table_query)
                    cur.execute(create_indices)
                    conn.commit()
                    logging.info("Successfully initialized database and created table")

        def insert_iambic_post(self, message_id, did, text, timestamp_us):
            """Insert an iambic post into the database."""
            with self.get_connection() as conn:
                with conn.cursor() as cur:
                    try:
                        query = """
                            INSERT INTO iambic_messages (message_id, did, post_text, timestamp_us)
                            VALUES (%s, %s, %s, %s)
                            ON CONFLICT (message_id) DO NOTHING
                        """
                        cur.execute(query, (message_id, did, text, timestamp_us))
                        conn.commit()
                        logging.info(f"Found and inserted iambic post: {text}")
                    except Exception as e:
                        logging.error(f"Error inserting post {message_id}: {e}")
                        raise

    class IambicMonitor:
        def __init__(self):
            self.db_manager = DatabaseManager()

        async def process_message(self, message):
            """Process a message from the firehose."""
            try:
                if (message.get('commit', {}).get('record', {}).get('text') and 
                    message['commit'].get('operation') == 'create' and 
                    message['commit'].get('collection') == 'app.bsky.feed.post'):
                    
                    text = message['commit']['record']['text']
                    
                    if check_iambic_pentameter(text):
                        self.db_manager.insert_iambic_post(
                            message['commit']['rkey'],
                            message['did'],
                            text,
                            message['time_us']
                        )
                
            except Exception as e:
                logging.error(f"Error processing message: {e}")

        async def monitor_firehose(self):
            """Connect to and monitor the Bluesky firehose."""
            while True:
                try:
                    async with websockets.connect('wss://bsky-relay.c.theo.io/subscribe?wantedCollections=app.bsky.feed.post') as websocket:
                        logging.info("Connected to Bluesky firehose")
                        
                        while True:
                            message = await websocket.recv()
                            await self.process_message(json.loads(message))
                            
                except Exception as e:
                    logging.error(f"WebSocket error: {e}")
                    await asyncio.sleep(5)
                    logging.info("Attempting to reconnect...")

        async def run(self):
            """Main run function."""
            self.db_manager.init_db()
            await self.monitor_firehose()

    if __name__ == "__main__":
        monitor = IambicMonitor()
        asyncio.run(monitor.run())

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: iambic-monitor
  namespace: bluesky
spec:
  replicas: 1
  selector:
    matchLabels:
      app: iambic-monitor
  template:
    metadata:
      labels:
        app: iambic-monitor
    spec:
      containers:
        - name: iambic-monitor
          image: python:3.9-slim
          command:
            - /bin/sh
            - -c
            - |
              pip install nltk websockets psycopg2-binary
              python iambic_monitor.py
          env:
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_DB
            - name: POSTGRES_PASSWORD
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_PASSWORD
          volumeMounts:
            - name: monitor-script
              mountPath: /app
          workingDir: /app
          resources:
            requests:
              memory: "112Mi"
              cpu: "50m"
            limits:
              memory: "1Gi"
              cpu: "500m"
      volumes:
        - name: monitor-script
          configMap:
            name: iambic-monitor-config
            items:
              - key: iambic_monitor.py
                path: iambic_monitor.py